**Edited by Chris Dai, 2021/01/29, Week 16**

## API updates

Over the past few weeks, we managed to create an API to interface with `Asterisk`, which is written in Python. Essentially, the program opens a file stream from Asterisk, analyse the content of the file, and detect whether there's a silence. If so, the program would then start converting the speech.

## Speech-to-text solution

With the API created, we then tested multiple speech to text solutions available and tried to pick the one that works best for our IVR system. Namely, they are `Mozilla DeepSpeech`, `IBM Watson`, `Google API` and `Pocketsphinx`.

### Mozilla DeepSpeech

Despite the upside of DeepSpeech which we went through in previous blog posts, the package size for DeepSpeech is too large for a language model (900+ MB), which makes it less suitable to our solution.

Moreover, DeepSpeech has a great performance in translating voice for audio with a rate of 16kHz. However, the regular telephone audio is sampled at 8kHz, and in such cases the DeepSpeech model doesn't work very well - even if the audio is upscaled to 16kHz. The successful rate of detect "yes" or "no" answer is only around 60% of the time.

### IBM Watson & Google API

Both solutions performed very well at translating the voice from file stream, resulting in a much greater chance in detecting "yes" or "no" answer. However, neither solution perform as well in the case when the audio is not as clear, which could happen very often for telephone audio.

Additionally, both solution require the usage of cloud, which is against our requirement due to GDPR. Although IBD Watson offers a choice to not store data on the cloud, it still requires the use of internet.

### Pocketsphinx

Pocketsphinx, a new solution we have been looking into, is a part of the CMU Sphinx open source toolkit for speech recognition. The solution was proven to be highly inaccurate in detecting exact text. However, the solution allows user to set particular words to look for. For example, when detecting the speech from Asterisk, the phrase we look for would be "yes", "yep", "yeah" and many more, increasing the possibility of getting the right answer. For such reason, a list of phrase was compiled for "yes" and "no" answer which makes it easier for Pocketsphinex to detect compare to generic sentence.

After testing, the solution was proven to be detecting more "yes" and "no" answer than it's supposed to be. Although it's not perfect, it still has an extremely high accuracy rate compare to other options. (Note: This does require using a separate open source speech model for 8kHz sample rate as well as upscaling the sample rate of the audio to 16kHz)

---

Overall, Pocketsphinx has a much higher rate of detecting correct answers compare to the alternative options. As such, it is currently being used in the API to detect the content of the audio file from Asterisk. The system now outputs "yes", "no" or "unsure" depending on the speech.

## **Next steps**

Reflecting from last week, we will continue to look into ways to test our system, make installation process simpler as well as improve the UI for our program.